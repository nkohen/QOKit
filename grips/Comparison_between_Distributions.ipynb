{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binomial distribution vs. Normal distribution\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters of the binomial distribution\n",
    "n = int(input(\"n = \"))\n",
    "p = float(input(\"The probability is \"))\n",
    "\n",
    "# The binomial distribution\n",
    "binom_rv = stats.binom(n, p)\n",
    "x = np.arange(0, n + 1)\n",
    "binom_pmf = binom_rv.pmf(x)\n",
    "\n",
    "# The approximation by the normal distribution\n",
    "mu = n * p\n",
    "sigma = np.sqrt(n * p * (1 - p))\n",
    "norm_rv = stats.norm(mu, sigma)\n",
    "norm_pmf = norm_rv.pdf(x)\n",
    "\n",
    "# The normal distribution\n",
    "continuous_norm_rv = stats.norm(mu, sigma)\n",
    "continuous_x = np.linspace(-n, n, 100)  # Setting the range of the normal distribution\n",
    "continuous_norm_pmf = continuous_norm_rv.pdf(continuous_x)\n",
    "\n",
    "# Graphs\n",
    "plt.bar(x, binom_pmf, alpha=0.5, label='Binomial')\n",
    "plt.plot(x, norm_pmf, 'r--', label='Normal approximation')\n",
    "plt.plot(continuous_x, continuous_norm_pmf, 'g-', label='Continuous Normal')\n",
    "plt.xlabel('k')  # x-axis\n",
    "plt.ylabel('Probability')  # y-axis\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binomial distribution vs. Poisson distribution\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters of the binomial distribution\n",
    "n = int(input(\"n = \"))\n",
    "p = float(input(\"The probability is \"))\n",
    "\n",
    "# The binomial distribution\n",
    "binom_rv = stats.binom(n, p)\n",
    "x = np.arange(0, n + 1)\n",
    "binom_pmf = binom_rv.pmf(x)\n",
    "\n",
    "# The approximation by Poisson distribution\n",
    "lambda_ = n * p\n",
    "poisson_rv = stats.poisson(lambda_)\n",
    "poisson_pmf = poisson_rv.pmf(x)\n",
    "\n",
    "# Graphs\n",
    "plt.bar(x, binom_pmf, alpha=0.5, label='Binomial')\n",
    "plt.plot(x, poisson_pmf, 'g-', label='Poisson approximation')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binomial distribution vs. the method by using Edgeworth expansion\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "\n",
    "# Parameters of the binomial distribution\n",
    "n = int(input(\"n = \"))\n",
    "p = float(input(\"The probability is \"))\n",
    "\n",
    "# The binomial distribution\n",
    "binom_rv = stats.binom(n, p)\n",
    "x = np.arange(0, n + 1)\n",
    "binom_pmf = binom_rv.pmf(x)\n",
    "\n",
    "# The function of Edgeworth expansion\n",
    "def edgeworth_expansion(x, n, p):\n",
    "    q = 1 - p\n",
    "    mu = n * p\n",
    "    sigma = np.sqrt(n * p * q)\n",
    "    z = (x - mu) / sigma\n",
    "    skewness = (q - p) / np.sqrt(n * p * q)\n",
    "    kurtosis = (1 - 6*p*q) / (n * p * q)\n",
    "\n",
    "    phi_z = stats.norm.pdf(z)\n",
    "    Phi_z = stats.norm.cdf(z)\n",
    "\n",
    "    correction = (1/6) * skewness * (z**2 - 1) * phi_z + (1/24) * kurtosis * (z**3 - 3*z) * phi_z - (1/36) * skewness**2 * (z**5 - 10*z**3 + 15*z) * phi_z\n",
    "\n",
    "    return Phi_z + correction\n",
    "\n",
    "# The approximation by using Edgeworth expansion\n",
    "edgeworth_cdf = edgeworth_expansion(x, n, p)\n",
    "edgeworth_pmf = np.diff(edgeworth_cdf, prepend=0)\n",
    "\n",
    "# Graphs\n",
    "plt.bar(x, binom_pmf, alpha=0.5, label='Binomial')\n",
    "plt.plot(x, edgeworth_pmf, 'b-', label='Edgeworth approximation')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binomial distribution vs. others\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "\n",
    "# Parameters of the binomial distribution\n",
    "n = int(input(\"n = \"))\n",
    "p = float(input(\"The probability is \"))\n",
    "\n",
    "# The binomial distribution\n",
    "binom_rv = stats.binom(n, p)\n",
    "x = np.arange(0, n + 1)\n",
    "binom_pmf = binom_rv.pmf(x)\n",
    "\n",
    "# The approximation by the normal distribution\n",
    "mu = n * p\n",
    "sigma = np.sqrt(n * p * (1 - p))\n",
    "norm_rv = stats.norm(mu, sigma)\n",
    "norm_pmf = norm_rv.pdf(x)\n",
    "\n",
    "# The normal distribution\n",
    "continuous_norm_rv = stats.norm(mu, sigma)\n",
    "continuous_x = np.linspace(-n, n, 100)  # Setting the range of the normal distribution\n",
    "continuous_norm_pmf = continuous_norm_rv.pdf(continuous_x)\n",
    "\n",
    "# The approximation by Poisson distribution\n",
    "lambda_ = n * p\n",
    "poisson_rv = stats.poisson(lambda_)\n",
    "poisson_pmf = poisson_rv.pmf(x)\n",
    "\n",
    "# The function of Edgeworth expansion\n",
    "def edgeworth_expansion(x, n, p):\n",
    "    q = 1 - p\n",
    "    mu = n * p\n",
    "    sigma = np.sqrt(n * p * q)\n",
    "    z = (x - mu) / sigma\n",
    "    skewness = (q - p) / np.sqrt(n * p * q)\n",
    "    kurtosis = (1 - 6*p*q) / (n * p * q)\n",
    "\n",
    "    phi_z = stats.norm.pdf(z)\n",
    "    Phi_z = stats.norm.cdf(z)\n",
    "\n",
    "    correction = (1/6) * skewness * (z**2 - 1) * phi_z + (1/24) * kurtosis * (z**3 - 3*z) * phi_z - (1/36) * skewness**2 * (z**5 - 10*z**3 + 15*z) * phi_z\n",
    "\n",
    "    return Phi_z + correction\n",
    "\n",
    "# The approximation by using Edgeworth expansion\n",
    "edgeworth_cdf = edgeworth_expansion(x, n, p)\n",
    "edgeworth_pmf = np.diff(edgeworth_cdf, prepend=0)\n",
    "\n",
    "# Graphs\n",
    "plt.bar(x, binom_pmf, alpha=0.5, label='Binomial')\n",
    "plt.plot(x, norm_pmf, label='Normal approximation')\n",
    "plt.plot(continuous_x, continuous_norm_pmf, 'r--', label='Continuous Normal')\n",
    "plt.plot(x, poisson_pmf, label='Poisson approximation')\n",
    "plt.plot(x, edgeworth_pmf, label='Edgeworth approximation')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison between distributions (n = '+str(n)+', probability: '+str(p)+')')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial distribution vs. others (without line graphs)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import dirichlet, multinomial\n",
    "\n",
    "# Parameter input\n",
    "categories = int(input(\"Number of categories = \"))\n",
    "trials = int(input(\"Number of trials = \"))\n",
    "\n",
    "# Parameter of Dirichlet distribution (Generating at ramdom)\n",
    "#alpha = np.array([float(input(f\"Dirichlet parameters of the category{i+1} = \")) for i in range(categories)])\n",
    "alpha = np.random.rand(categories) + 1 # Generating random numbers greater than or equal to one to ensure that the sum of the probabilities is equal to one.\n",
    "\n",
    "# Parameter of Poisson distribution (Generating at ramdom)\n",
    "#lambdas = np.array([float(input(f\"Poisson parameter Î» of the category{i+1} = \")) for i in range(categories)])\n",
    "lambdas = np.random.rand(categories) * 10 # Generating a random number between 0 and 10. \n",
    "\n",
    "# Transition matrix of a Markov chain.\n",
    "transition_matrix = np.random.rand(categories, categories)\n",
    "transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Seting the initial state distribution evenly\n",
    "initial_state_distribution = np.full(categories, 1.0 / categories)\n",
    "\n",
    "# Randomly generated and normalised parameters (probabilities) of a multinomial distribution\n",
    "true_probs = np.random.rand(categories)\n",
    "true_probs /= true_probs.sum()\n",
    "\n",
    "# Generating samples from a multinomial distribution\n",
    "samples_multinomial = multinomial.rvs(n=trials, p=true_probs, size=1)\n",
    "approx_multinomial = samples_multinomial[0] / trials\n",
    "\n",
    "# Approximation by using Dirichlet distribution\n",
    "samples_dirichlet = dirichlet.rvs(alpha, size=trials)\n",
    "approx_multinomial_dirichlet = np.mean(samples_dirichlet, axis=0)\n",
    "\n",
    "# Approximation by using Poisson distribution\n",
    "samples_poisson = np.random.poisson(lambdas, size=(trials, categories))\n",
    "approx_multinomial_poisson = np.mean(samples_poisson / np.sum(samples_poisson, axis=1, keepdims=True), axis=0)\n",
    "\n",
    "# Approximation by using a Markov chain\n",
    "states = np.zeros((trials, categories))\n",
    "current_state = np.random.choice(categories, p=initial_state_distribution)\n",
    "states[0, current_state] = 1\n",
    "\n",
    "for t in range(1, trials):\n",
    "    current_state = np.random.choice(categories, p=transition_matrix[current_state])\n",
    "    states[t, current_state] = 1\n",
    "\n",
    "approx_multinomial_markov = np.mean(states, axis=0)\n",
    "\n",
    "# Plots\n",
    "labels = [f\"{i+1}\" for i in range(categories)] #Each category\n",
    "x = np.arange(categories)\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x - 1.5*width, approx_multinomial, width, label='True Multinomial')\n",
    "ax.bar(x - 0.5*width, approx_multinomial_dirichlet, width, label='Dirichlet')\n",
    "ax.bar(x + 0.5*width, approx_multinomial_poisson, width, label='Poisson')\n",
    "ax.bar(x + 1.5*width, approx_multinomial_markov, width, label='Markov')\n",
    "\n",
    "ax.set_xlabel('Categories')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Approximations to multinomial ('+str(trials)+' trials)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial distribution vs. others (with line graphs)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import dirichlet, multinomial\n",
    "\n",
    "# Parameter input\n",
    "categories = int(input(\"Number of categories = \"))\n",
    "trials = int(input(\"Number of trials = \"))\n",
    "\n",
    "# Parameter of Dirichlet distribution (Generating at ramdom)\n",
    "#alpha = np.array([float(input(f\"Dirichlet parameters of the category{i+1} = \")) for i in range(categories)])\n",
    "alpha = np.random.rand(categories) + 1 # Generating random numbers greater than or equal to one to ensure that the sum of the probabilities is equal to one.\n",
    "\n",
    "# Parameter of Poisson distribution (Generating at ramdom)\n",
    "#lambdas = np.array([float(input(f\"Poisson parameter Î» of the category{i+1} = \")) for i in range(categories)])\n",
    "lambdas = np.random.rand(categories) * 10 # Generating a random number between 0 and 10. \n",
    "\n",
    "# Transition matrix of a Markov chain.\n",
    "transition_matrix = np.random.rand(categories, categories)\n",
    "transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Seting the initial state distribution evenly\n",
    "initial_state_distribution = np.full(categories, 1.0 / categories)\n",
    "\n",
    "# Randomly generated and normalised parameters (probabilities) of a multinomial distribution\n",
    "true_probs = np.random.rand(categories)\n",
    "true_probs /= true_probs.sum()\n",
    "\n",
    "# Generating samples from a multinomial distribution\n",
    "samples_multinomial = multinomial.rvs(n=trials, p=true_probs, size=1)\n",
    "approx_multinomial = samples_multinomial[0] / trials\n",
    "\n",
    "# Approximation by using Dirichlet distribution\n",
    "samples_dirichlet = dirichlet.rvs(alpha, size=trials)\n",
    "approx_multinomial_dirichlet = np.mean(samples_dirichlet, axis=0)\n",
    "\n",
    "# Approximation by using Poisson distribution\n",
    "samples_poisson = np.random.poisson(lambdas, size=(trials, categories))\n",
    "approx_multinomial_poisson = np.mean(samples_poisson / np.sum(samples_poisson, axis=1, keepdims=True), axis=0)\n",
    "\n",
    "# Approximation by using a Markov chain\n",
    "states = np.zeros((trials, categories))\n",
    "current_state = np.random.choice(categories, p=initial_state_distribution)\n",
    "states[0, current_state] = 1\n",
    "\n",
    "for t in range(1, trials):\n",
    "    current_state = np.random.choice(categories, p=transition_matrix[current_state])\n",
    "    states[t, current_state] = 1\n",
    "\n",
    "approx_multinomial_markov = np.mean(states, axis=0)\n",
    "\n",
    "# Plots\n",
    "labels = [f\"{i+1}\" for i in range(categories)] #Each category\n",
    "x = np.arange(categories)\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.bar(x - 1.5*width, approx_multinomial, width, label='True Multinomial')\n",
    "ax.bar(x - 0.5*width, approx_multinomial_dirichlet, width, label='Dirichlet')\n",
    "ax.bar(x + 0.5*width, approx_multinomial_poisson, width, label='Poisson')\n",
    "ax.bar(x + 1.5*width, approx_multinomial_markov, width, label='Markov')\n",
    "\n",
    "ax.plot(x, approx_multinomial, marker='o', linestyle='-', label='True Multinomial')\n",
    "ax.plot(x, approx_multinomial_dirichlet, marker='o', linestyle='-', label='Dirichlet')\n",
    "ax.plot(x, approx_multinomial_poisson, marker='o', linestyle='-', label='Poisson')\n",
    "ax.plot(x, approx_multinomial_markov, marker='o', linestyle='-', label='Markov')\n",
    "\n",
    "ax.set_xlabel('Categories')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Comparison between multinomial and others ('+str(trials)+' trials)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of Binomial Distribution and Its Approximations\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "n = int(input(\"n = \"))\n",
    "p = float(input(\"The probability is \"))\n",
    "\n",
    "# The binomial distribution\n",
    "binom_rv = stats.binom(n, p)\n",
    "x = np.arange(0, n + 1)\n",
    "binom_pmf = binom_rv.pmf(x)\n",
    "\n",
    "# Normal approximation\n",
    "mu = n * p\n",
    "sigma = np.sqrt(n * p * (1 - p))\n",
    "norm_rv = stats.norm(mu, sigma)\n",
    "norm_pmf = norm_rv.pdf(x)\n",
    "\n",
    "# Continuous normal distribution\n",
    "continuous_norm_rv = stats.norm(mu, sigma)\n",
    "continuous_x = np.linspace(-n, n, 100)  \n",
    "continuous_norm_pmf = continuous_norm_rv.pdf(continuous_x)\n",
    "\n",
    "# Poisson approximation\n",
    "lambda_ = n * p\n",
    "poisson_rv = stats.poisson(lambda_)\n",
    "poisson_pmf = poisson_rv.pmf(x)\n",
    "\n",
    "# Edgeworth expansion\n",
    "def edgeworth_expansion(x, n, p):\n",
    "    q = 1 - p\n",
    "    mu = n * p\n",
    "    sigma = np.sqrt(n * p * q)\n",
    "    z = (x - mu) / sigma\n",
    "    skewness = (q - p) / np.sqrt(n * p * q)\n",
    "    kurtosis = (1 - 6*p*q) / (n * p * q)\n",
    "\n",
    "    phi_z = stats.norm.pdf(z)\n",
    "    Phi_z = stats.norm.cdf(z)\n",
    "\n",
    "    correction = (1/6) * skewness * (z**2 - 1) * phi_z + (1/24) * kurtosis * (z**3 - 3*z) * phi_z - (1/36) * skewness**2 * (z**5 - 10*z**3 + 15*z) * phi_z\n",
    "\n",
    "    return Phi_z + correction\n",
    "\n",
    "# Measuring execution time for each approximation\n",
    "def measure_time_and_accuracy():    \n",
    "    start_time = time.time()\n",
    "    binom_rv = stats.binom(n, p)\n",
    "    binom_pmf = binom_rv.pmf(x)\n",
    "    binom_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    norm_rv = stats.norm(mu, sigma)\n",
    "    norm_pmf = norm_rv.pdf(x)\n",
    "    norm_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    poisson_rv = stats.poisson(lambda_)\n",
    "    poisson_pmf = poisson_rv.pmf(x)\n",
    "    poisson_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    edgeworth_cdf = edgeworth_expansion(x, n, p)\n",
    "    edgeworth_pmf = np.diff(edgeworth_cdf, prepend=0)\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    return binom_pmf, binom_time, norm_pmf, norm_time, poisson_pmf, poisson_time, edgeworth_pmf, edgeworth_time\n",
    "\n",
    "binom_pmf, binom_time, norm_pmf, norm_time, poisson_pmf, poisson_time, edgeworth_pmf, edgeworth_time = measure_time_and_accuracy()\n",
    "\n",
    "# Accuracy measures\n",
    "def calculate_accuracy(true_pmf, approx_pmf):\n",
    "    return np.mean(np.abs(true_pmf - approx_pmf))\n",
    "def calculate_mse(true_pmf, approx_pmf):\n",
    "    return np.mean((true_pmf - approx_pmf) ** 2)\n",
    "\n",
    "binom_accuracy = calculate_accuracy(binom_pmf, binom_pmf)\n",
    "norm_accuracy = calculate_accuracy(binom_pmf, norm_pmf)\n",
    "poisson_accuracy = calculate_accuracy(binom_pmf, poisson_pmf)\n",
    "edgeworth_accuracy = calculate_accuracy(binom_pmf, edgeworth_pmf)\n",
    "binom_mse = calculate_mse(binom_pmf, binom_pmf)\n",
    "norm_mse = calculate_mse(binom_pmf, norm_pmf)\n",
    "poisson_mse = calculate_mse(binom_pmf, poisson_pmf)\n",
    "edgeworth_mse = calculate_mse(binom_pmf, edgeworth_pmf)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Probability mass functions comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(x, binom_pmf, alpha=0.5, label='Binomial distribution', color='black')\n",
    "plt.plot(x, norm_pmf, label='Normal approximation')\n",
    "plt.plot(continuous_x, continuous_norm_pmf, 'r--', label='Continuous Normal')\n",
    "plt.plot(x, poisson_pmf, label='Poisson approximation')\n",
    "plt.plot(x, edgeworth_pmf, label='Edgeworth approximation')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability Mass Functions Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Execution time comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Binomial', 'Normal', 'Poisson', 'Edgeworth']\n",
    "times = [binom_time, norm_time, poisson_time, edgeworth_time]\n",
    "plt.bar(methods, times, color=['black', 'blue', 'orange', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Normal', 'Poisson', 'Edgeworth']\n",
    "accuracies = [norm_accuracy, poisson_accuracy, edgeworth_accuracy]\n",
    "plt.bar(methods, accuracies, color=['blue', 'orange', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Accuracy Comparison 1')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Normal', 'Poisson', 'Edgeworth']\n",
    "mses = [norm_mse, poisson_mse, edgeworth_mse]\n",
    "plt.bar(methods, mses, color=['blue', 'orange', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Accuracy Comparison 2')\n",
    "\n",
    "#plt.suptitle('Comparison of Binomial Distribution and Its Approximations (Number of trials: '+str(n)+', probability: '+str(p)+')', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suggestion 1 by THE TEACHER\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.special import factorial\n",
    "\n",
    "def multinomial_pmf(x, n, p):\n",
    "    coeff = factorial(n) / np.prod(factorial(x))\n",
    "    prob = coeff * np.prod(p**x)\n",
    "    return prob\n",
    "\n",
    "def edgeworth_expansion_multinomial(x, n, p):\n",
    "    p = np.array(p)\n",
    "    q = 1 - p\n",
    "    mu = n * p\n",
    "    sigma = np.sqrt(n * p * q)\n",
    "    \n",
    "    # Calculate the covariance matrix\n",
    "    cov = np.diag(n * p * q)\n",
    "    \n",
    "    # Calculate the skewness and kurtosis tensors\n",
    "    skewness = (q - p) / np.sqrt(n * p * q)\n",
    "    kurtosis = (1 - 6*p*q) / (n * p * q)\n",
    "    \n",
    "    z = (x - mu) / sigma\n",
    "    \n",
    "    # Calculate the multivariate normal PDF\n",
    "    mvn = stats.multivariate_normal(mu, cov)\n",
    "    phi_z = mvn.pdf(x)\n",
    "    \n",
    "    # Calculate the correction terms\n",
    "    correction = (1/6) * np.sum(skewness * (z**2 - 1)) * phi_z + \\\n",
    "                 (1/24) * np.sum(kurtosis * (z**3 - 3*z)) * phi_z - \\\n",
    "                 (1/36) * np.sum(skewness**2 * (z**5 - 10*z**3 + 15*z)) * phi_z\n",
    "\n",
    "    return phi_z + correction\n",
    "\n",
    "def measure_time_and_accuracy_multinomial(n, p, num_samples):\n",
    "    outcomes = np.random.multinomial(n, p, num_samples)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    binom_pmf = np.array([multinomial_pmf(x, n, p) for x in outcomes])\n",
    "    binom_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    edgeworth_pmf = np.array([edgeworth_expansion_multinomial(x, n, p) for x in outcomes])\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    return outcomes, binom_pmf, binom_time, edgeworth_pmf, edgeworth_time\n",
    "\n",
    "def calculate_accuracy(true_pmf, approx_pmf):\n",
    "    return np.mean(np.abs(true_pmf - approx_pmf))\n",
    "\n",
    "def calculate_mse(true_pmf, approx_pmf):\n",
    "    return np.mean((true_pmf - approx_pmf) ** 2)\n",
    "\n",
    "# Parameters\n",
    "n = int(input(\"n = \"))\n",
    "p = list(map(float, input(\"Probabilities (comma-separated) = \").split(',')))\n",
    "num_samples = 100  # Number of samples to evaluate\n",
    "\n",
    "outcomes, binom_pmf, binom_time, edgeworth_pmf, edgeworth_time = measure_time_and_accuracy_multinomial(n, p, num_samples)\n",
    "\n",
    "binom_accuracy = calculate_accuracy(binom_pmf, binom_pmf)\n",
    "edgeworth_accuracy = calculate_accuracy(binom_pmf, edgeworth_pmf)\n",
    "binom_mse = calculate_mse(binom_pmf, binom_pmf)\n",
    "edgeworth_mse = calculate_mse(binom_pmf, edgeworth_pmf)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Probability mass functions comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "indices = np.arange(len(outcomes))\n",
    "plt.bar(indices, binom_pmf, alpha=0.5, label='Multinomial distribution', color='black')\n",
    "plt.plot(indices, edgeworth_pmf, 'g-', label='Edgeworth approximation')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability Mass Functions Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Execution time comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Multinomial', 'Edgeworth']\n",
    "times = [binom_time, edgeworth_time]\n",
    "plt.bar(methods, times, color=['black', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Edgeworth']\n",
    "accuracies = [edgeworth_accuracy]\n",
    "plt.bar(methods, accuracies, color=['green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Accuracy Comparison (MAE)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Edgeworth']\n",
    "mses = [edgeworth_mse]\n",
    "plt.bar(methods, mses, color=['green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Accuracy Comparison (MSE)')\n",
    "\n",
    "plt.suptitle('Comparison of Multinomial Distribution and Edgeworth Approximation (n = '+str(n)+', p = '+str(p)+')', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suggestion 2 by THE TEACHER\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "n = int(input(\"n = \"))\n",
    "p = list(map(float, input(\"The probabilities are (space-separated): \").split()))\n",
    "\n",
    "# Generating sample outcomes from the multinomial distribution\n",
    "num_samples = 1000\n",
    "samples = np.random.multinomial(n, p, num_samples)\n",
    "\n",
    "# Normal approximation for multinomial distribution\n",
    "mu = n * np.array(p)\n",
    "sigma = np.sqrt(n * np.array(p) * (1 - np.array(p)))\n",
    "cov_matrix = np.diag(sigma**2)\n",
    "\n",
    "# Edgeworth expansion for multinomial distribution\n",
    "def edgeworth_expansion_multinomial(x, n, p):\n",
    "    p = np.array(p)\n",
    "    q = 1 - p\n",
    "    mu = n * p\n",
    "    sigma = np.sqrt(n * p * q)\n",
    "    \n",
    "    # Calculate the covariance matrix\n",
    "    cov = np.diag(n * p * q)\n",
    "    \n",
    "    # Calculate the skewness and kurtosis tensors\n",
    "    skewness = (q - p) / np.sqrt(n * p * q)\n",
    "    kurtosis = (1 - 6*p*q) / (n * p * q)\n",
    "    \n",
    "    z = (x - mu) / sigma\n",
    "    \n",
    "    # Calculate the multivariate normal PDF\n",
    "    mvn = stats.multivariate_normal(mu, cov)\n",
    "    phi_z = mvn.pdf(x)\n",
    "    \n",
    "    # Calculate the correction terms\n",
    "    correction = (1/6) * np.sum(skewness * (z**2 - 1)) * phi_z + \\\n",
    "                 (1/24) * np.sum(kurtosis * (z**3 - 3*z)) * phi_z - \\\n",
    "                 (1/36) * np.sum(skewness**2 * (z**5 - 10*z**3 + 15*z)) * phi_z\n",
    "\n",
    "    return phi_z + correction\n",
    "\n",
    "# Measuring execution time for each approximation\n",
    "def measure_time_and_accuracy_multinomial(samples):\n",
    "    start_time = time.time()\n",
    "    multinom_pmf = np.array([stats.multinomial.pmf(sample, n, p) for sample in samples])\n",
    "    multinom_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    norm_pmf = np.array([stats.multivariate_normal.pdf(sample, mu, cov_matrix) for sample in samples])\n",
    "    norm_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    edgeworth_pmf = np.array([edgeworth_expansion_multinomial(sample, n, p) for sample in samples])\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    return multinom_pmf, multinom_time, norm_pmf, norm_time, edgeworth_pmf, edgeworth_time\n",
    "\n",
    "multinom_pmf, multinom_time, norm_pmf, norm_time, edgeworth_pmf, edgeworth_time = measure_time_and_accuracy_multinomial(samples)\n",
    "\n",
    "# Accuracy measures\n",
    "def calculate_accuracy(true_pmf, approx_pmf):\n",
    "    return np.mean(np.abs(true_pmf - approx_pmf))\n",
    "def calculate_mse(true_pmf, approx_pmf):\n",
    "    return np.mean((true_pmf - approx_pmf) ** 2)\n",
    "\n",
    "norm_accuracy = calculate_accuracy(multinom_pmf, norm_pmf)\n",
    "edgeworth_accuracy = calculate_accuracy(multinom_pmf, edgeworth_pmf)\n",
    "norm_mse = calculate_mse(multinom_pmf, norm_pmf)\n",
    "edgeworth_mse = calculate_mse(multinom_pmf, edgeworth_pmf)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Probability mass functions comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "indices = np.arange(len(samples))\n",
    "plt.bar(indices, multinom_pmf, alpha=0.5, label='Multinomial distribution', color='black')\n",
    "plt.plot(indices, norm_pmf, label='Normal approximation', color='blue')\n",
    "plt.plot(indices, edgeworth_pmf, label='Edgeworth approximation', color='green')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability Mass Functions Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Execution time comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Multinomial', 'Normal', 'Edgeworth']\n",
    "times = [multinom_time, norm_time, edgeworth_time]\n",
    "plt.bar(methods, times, color=['black', 'blue', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Normal', 'Edgeworth']\n",
    "accuracies = [norm_accuracy, edgeworth_accuracy]\n",
    "plt.bar(methods, accuracies, color=['blue', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Accuracy Comparison 1')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Normal', 'Edgeworth']\n",
    "mses = [norm_mse, edgeworth_mse]\n",
    "plt.bar(methods, mses, color=['blue', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Accuracy Comparison 2')\n",
    "\n",
    "plt.suptitle('Comparison of Multinomial Distribution and Its Approximations (n = '+str(n)+', p = '+str(p)+')', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "categories = int(input(\"Number of categories: \"))\n",
    "trials = int(input(\"Number of trials: \"))\n",
    "\n",
    "# Generating the parameter of Dirichlet distribution at random\n",
    "alpha = np.random.rand(categories) + 1  # Generating a random number greater than 1 to make the sum of probabilities 1\n",
    "\n",
    "# Generating the parameter of Poisson distribution at random\n",
    "lambdas = np.random.rand(categories) * 10  # Generating a random number between 0 and 10\n",
    "\n",
    "# Generating a transition matrix for a Markov chain using random numbers and normalizing each row to 1.\n",
    "transition_matrix = np.random.rand(categories, categories)\n",
    "transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Setting the initial state distribution evenly\n",
    "initial_state_distribution = np.full(categories, 1.0 / categories)\n",
    "\n",
    "# Generating and normalizing randomly the parameters (probabilities) of the multinomial distribution\n",
    "true_probs = np.random.rand(categories)\n",
    "true_probs /= true_probs.sum()\n",
    "\n",
    "# Generating a sample from a multinomial distribution\n",
    "samples_multinomial = stats.multinomial.rvs(n=trials, p=true_probs, size=1)\n",
    "approx_multinomial = samples_multinomial[0] / trials\n",
    "\n",
    "# Approximation by Dirichlet distribution\n",
    "samples_dirichlet = stats.dirichlet.rvs(alpha, size=trials)\n",
    "approx_multinomial_dirichlet = np.mean(samples_dirichlet, axis=0)\n",
    "\n",
    "# Approximation by Poisson distribution\n",
    "samples_poisson = np.random.poisson(lambdas, size=(trials, categories))\n",
    "approx_multinomial_poisson = np.mean(samples_poisson / np.sum(samples_poisson, axis=1, keepdims=True), axis=0)\n",
    "\n",
    "# Approximation by a Markov chain\n",
    "states = np.zeros((trials, categories))\n",
    "current_state = np.random.choice(categories, p=initial_state_distribution)\n",
    "states[0, current_state] = 1\n",
    "\n",
    "for t in range(1, trials):\n",
    "    current_state = np.random.choice(categories, p=transition_matrix[current_state])\n",
    "    states[t, current_state] = 1\n",
    "\n",
    "approx_multinomial_markov = np.mean(states, axis=0)\n",
    "\n",
    "#  Approximation by Edgeworth expansion\n",
    "def edgeworth_expansion(true_probs, trials, categories):\n",
    "    mu = true_probs\n",
    "    sigma2 = (true_probs * (1 - true_probs)) / trials\n",
    "    skewness = (1 - 2 * true_probs) / np.sqrt(trials * sigma2)\n",
    "    \n",
    "    correction = np.zeros(categories)\n",
    "    for i in range(categories):\n",
    "        z = (true_probs[i] - mu[i]) / np.sqrt(sigma2[i])\n",
    "        phi_z = stats.norm.pdf(z)\n",
    "        Phi_z = stats.norm.cdf(z)\n",
    "        correction[i] = Phi_z + (1/6) * skewness[i] * (z**2 - 1) * phi_z\n",
    "\n",
    "    return correction\n",
    "\n",
    "approx_multinomial_edgeworth = edgeworth_expansion(true_probs, trials, categories)\n",
    "\n",
    "# Measurement of runtime\n",
    "def measure_time():\n",
    "    start_time = time.time()\n",
    "    samples_multinomial = stats.multinomial.rvs(n=trials, p=true_probs, size=1)\n",
    "    approx_multinomial = samples_multinomial[0] / trials\n",
    "    binom_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    samples_dirichlet = stats.dirichlet.rvs(alpha, size=trials)\n",
    "    approx_multinomial_dirichlet = np.mean(samples_dirichlet, axis=0)\n",
    "    dirichlet_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    samples_poisson = np.random.poisson(lambdas, size=(trials, categories))\n",
    "    approx_multinomial_poisson = np.mean(samples_poisson / np.sum(samples_poisson, axis=1, keepdims=True), axis=0)\n",
    "    poisson_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    states = np.zeros((trials, categories))\n",
    "    current_state = np.random.choice(categories, p=initial_state_distribution)\n",
    "    states[0, current_state] = 1\n",
    "\n",
    "    for t in range(1, trials):\n",
    "        current_state = np.random.choice(categories, p=transition_matrix[current_state])\n",
    "        states[t, current_state] = 1\n",
    "\n",
    "    approx_multinomial_markov = np.mean(states, axis=0)\n",
    "    markov_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    edgeworth_exp = edgeworth_expansion(true_probs, trials, categories)\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    return binom_time, dirichlet_time, poisson_time, markov_time, edgeworth_time\n",
    "\n",
    "binom_time, dirichlet_time, poisson_time, markov_time, edgeworth_time = measure_time()\n",
    "\n",
    "# Calculation of accuracy\n",
    "def calculate_accuracy(true_probs, approx_probs):\n",
    "    return np.mean(np.abs(true_probs - approx_probs))\n",
    "\n",
    "def calculate_mse(true_probs, approx_probs):\n",
    "    return np.mean((true_probs - approx_probs) ** 2)\n",
    "\n",
    "dirichlet_accuracy = calculate_accuracy(approx_multinomial, approx_multinomial_dirichlet)\n",
    "poisson_accuracy = calculate_accuracy(approx_multinomial, approx_multinomial_poisson)\n",
    "markov_accuracy = calculate_accuracy(approx_multinomial, approx_multinomial_markov)\n",
    "edgeworth_accuracy = calculate_accuracy(approx_multinomial, approx_multinomial_edgeworth)\n",
    "dirichlet_mse = calculate_mse(approx_multinomial, approx_multinomial_dirichlet)\n",
    "poisson_mse = calculate_mse(approx_multinomial, approx_multinomial_poisson)\n",
    "markov_mse = calculate_mse(approx_multinomial, approx_multinomial_markov)\n",
    "edgeworth_mse = calculate_mse(approx_multinomial, approx_multinomial_edgeworth)\n",
    "\n",
    "# Plotting\n",
    "labels = [f\"the category {i+1}\" for i in range(categories)]\n",
    "x = np.arange(categories)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Line graph of results\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x, approx_multinomial, marker='o', linestyle='-', label='True Multinomial')\n",
    "plt.plot(x, approx_multinomial_dirichlet, marker='o', linestyle='-', label='Dirichlet')\n",
    "plt.plot(x, approx_multinomial_poisson, marker='o', linestyle='-', label='Poisson')\n",
    "plt.plot(x, approx_multinomial_markov, marker='o', linestyle='-', label='Markov')\n",
    "plt.plot(x, approx_multinomial_edgeworth, marker='o', linestyle='-', label='Edgeworth')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Randomized samples')\n",
    "plt.xticks(x, labels)\n",
    "plt.legend()\n",
    "\n",
    "# Comparison of runtime\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Multinomial', 'Dirichlet', 'Poisson', 'Markov', 'Edgeworth']\n",
    "times = [binom_time, dirichlet_time, poisson_time, markov_time, edgeworth_time]\n",
    "plt.bar(methods, times, color=['black', 'blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Comparison of accuracy about MAE\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Dirichlet', 'Poisson', 'Markov', 'Edgeworth']\n",
    "accuracies = [dirichlet_accuracy, poisson_accuracy, markov_accuracy, edgeworth_accuracy]\n",
    "plt.bar(methods, accuracies, color=['blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Accuracy Comparison (Mean Absolute Error)')\n",
    "\n",
    "# Comparison of accuracy about MSE\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Dirichlet', 'Poisson', 'Markov', 'Edgeworth']\n",
    "mses = [dirichlet_mse, poisson_mse, markov_mse, edgeworth_mse]\n",
    "plt.bar(methods, mses, color=['blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Accuracy Comparison (Mean Squared Error)')\n",
    "\n",
    "plt.suptitle('Comparison of Multinomial Distribution and Its Approximations (Categories = '+str(categories)+', Trials = '+str(trials)+')', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial\n",
    "from scipy.special import gammaln#gamma\n",
    "\n",
    "def continuous_deformation_of_multinomial_pdf(x, n, p):\n",
    "    if len(x) != len(p):\n",
    "        raise ValueError(\"Length of x and p must be the same!\")\n",
    "    if not np.isclose(sum(x), 1):\n",
    "        return 0\n",
    "    try:\n",
    "        #numerator = gamma(n-1)\n",
    "        log_numerator = gammaln(n) - gammaln(n-1)#gammaln(n-1)\n",
    "        #denominator = 1\n",
    "        log_denominator = sum(gammaln((n-1)*pi) for pi in p)\n",
    "        '''\n",
    "        for pi in p:\n",
    "            denominator *= gamma((n-1)*pi)\n",
    "        variables_product = 1\n",
    "        for xi, pi in zip(x, p):\n",
    "            if xi == 0 and (n-1)*pi-1 < 0:\n",
    "                return 0\n",
    "            variables_product *= xi**((n-1)*pi-1)\n",
    "        pmf = numerator/(denominator*variables_product)\n",
    "        '''\n",
    "        log_variables_product = 0\n",
    "        for xi, pi in zip(x, p):\n",
    "            if xi == 0:\n",
    "                if (n-1)*pi-1 < 0:\n",
    "                    return 0\n",
    "                continue\n",
    "            log_variables_product += ((n-1)*pi-1)*np.log(xi)\n",
    "        log_pmf = log_numerator - log_denominator - log_variables_product\n",
    "        pmf = np.exp(log_pmf)\n",
    "        return pmf\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Input\n",
    "#n = int(input(\"Number of trials: \"))\n",
    "max_n = int(input(\"Enter the maximum number of trials (n): \"))\n",
    "k = 4#int(input(\"Number of categories: \"))\n",
    "\n",
    "# Prepare for plotting\n",
    "n_values = range(1, max_n + 1)\n",
    "continuous_values = []\n",
    "multinomial_values = []\n",
    "\n",
    "'''\n",
    "# Randomly generating p and x based on the p\n",
    "np.random.seed(42)  # For reproducibility\n",
    "p = np.random.dirichlet(np.ones(k))  # Probability vector of k-th categories\n",
    "x = np.random.multinomial(n, p)  # Generation of x\n",
    "\n",
    "# Calculation of continuous_deformation_of_multinomial_pdf\n",
    "cdf_continuous = continuous_deformation_of_multinomial_pdf(x / n, n, p)\n",
    "\n",
    "# Calculation of multinomial.pmf\n",
    "cdf_multinomial = multinomial.pmf(x, n, p)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Continuous Deformation', 'Multinomial'], [cdf_continuous, cdf_multinomial], color=['blue', 'green'])\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison between Multinomial and Its Continuous Deformation')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# For each n, compute probabilities and store them\n",
    "for n in n_values:\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    p = np.random.dirichlet(np.ones(k))  # Probability vector of k-th categories\n",
    "    x = np.random.multinomial(n, p)  # Generation of x\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    cdf_continuous = continuous_deformation_of_multinomial_pdf(x / n, n, p)\n",
    "    cdf_multinomial = multinomial.pmf(x, n, p)\n",
    "    \n",
    "    continuous_values.append(cdf_continuous)\n",
    "    multinomial_values.append(cdf_multinomial)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_values, continuous_values, label='Continuous Deformation', marker='o')\n",
    "plt.plot(n_values, multinomial_values, label='Multinomial', marker='x')\n",
    "plt.xlabel('Number of Trials (n)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison between Multinomial and Its Continuous Deformation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, max(max(continuous_values), max(multinomial_values)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial\n",
    "from scipy.special import gammaln\n",
    "\n",
    "def continuous_deformation_of_multinomial_pdf(x, n, p):\n",
    "    if len(x) != len(p):\n",
    "        raise ValueError(\"Length of x and p must be the same!\")\n",
    "    if not np.isclose(sum(x), 1):\n",
    "        return 0\n",
    "    try:\n",
    "        log_numerator = gammaln(n) - gammaln(n-1)  # Corrected calculation\n",
    "        log_denominator = sum(gammaln((n-1)*pi) for pi in p)\n",
    "        \n",
    "        log_variables_product = 0\n",
    "        for xi, pi in zip(x, p):\n",
    "            if xi <= 0:\n",
    "                if (n-1)*pi-1 < 0:\n",
    "                    return 0\n",
    "                continue\n",
    "            log_variables_product += ((n-1)*pi-1) * np.log(xi)\n",
    "        \n",
    "        log_pmf = log_numerator - log_denominator - log_variables_product\n",
    "        pmf = np.exp(log_pmf)\n",
    "        \n",
    "        return pmf\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Input\n",
    "max_n = int(input(\"Enter the maximum number of trials (n): \"))\n",
    "k = 4  # Number of categories\n",
    "\n",
    "# Prepare for plotting\n",
    "n_values = range(1, max_n + 1)\n",
    "continuous_values = []\n",
    "multinomial_values = []\n",
    "\n",
    "# For each n, compute probabilities and store them\n",
    "for n in n_values:\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    p = np.random.dirichlet(np.ones(k))  # Probability vector of k-th categories\n",
    "    x = np.random.multinomial(n, p)  # Generation of x\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    cdf_continuous = continuous_deformation_of_multinomial_pdf(x / n, n, p)\n",
    "    cdf_multinomial = multinomial.pmf(x, n, p)\n",
    "    \n",
    "    continuous_values.append(cdf_continuous)\n",
    "    multinomial_values.append(cdf_multinomial)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_values, continuous_values, label='Continuous Deformation', marker='o')\n",
    "plt.plot(n_values, multinomial_values, label='Multinomial', marker='x')\n",
    "plt.xlabel('Number of Trials (n)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison between Multinomial and Its Continuous Deformation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, max(max(continuous_values), max(multinomial_values)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial\n",
    "from scipy.special import gamma\n",
    "\n",
    "def continuous_deformation_of_multinomial_pdf(x, n, p):\n",
    "    if len(x) != len(p):\n",
    "        raise ValueError(\"Length of x and p must be the same!\")\n",
    "    if not np.isclose(sum(x), 1):\n",
    "        return 0\n",
    "    try:\n",
    "        # Compute the numerator\n",
    "        numerator = gamma(n - 1)\n",
    "        \n",
    "        # Compute the denominator\n",
    "        denominator = 1\n",
    "        for pi in p:\n",
    "            denominator *= gamma((n - 1) * pi)\n",
    "        \n",
    "        # Compute the product of x^(n-1)*pi - 1\n",
    "        variables_product = 1\n",
    "        for xi, pi in zip(x, p):\n",
    "            if xi == 0 and (n - 1) * pi - 1 < 0:\n",
    "                return 0\n",
    "            variables_product *= xi**((n - 1) * pi - 1)\n",
    "        \n",
    "        # Compute the PMF\n",
    "        pmf = numerator / (denominator * variables_product)\n",
    "        return pmf\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Input\n",
    "max_n = int(input(\"Enter the maximum number of trials (n): \"))\n",
    "k = 4  # Number of categories\n",
    "\n",
    "# Prepare for plotting\n",
    "n_values = range(1, max_n + 1)\n",
    "continuous_values = []\n",
    "multinomial_values = []\n",
    "\n",
    "# For each n, compute probabilities and store them\n",
    "for n in n_values:\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    p = np.random.dirichlet(np.ones(k))  # Probability vector of k-th categories\n",
    "    x = np.random.multinomial(n, p)  # Generation of x\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    cdf_continuous = continuous_deformation_of_multinomial_pdf(x / n, n, p)\n",
    "    cdf_multinomial = multinomial.pmf(x, n, p)\n",
    "    \n",
    "    continuous_values.append(cdf_continuous)\n",
    "    multinomial_values.append(cdf_multinomial)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_values, continuous_values, label='Continuous Deformation', marker='o')\n",
    "plt.plot(n_values, multinomial_values, label='Multinomial', marker='x')\n",
    "plt.xlabel('Number of Trials (n)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison between Multinomial and Its Continuous Deformation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, max(max(continuous_values), max(multinomial_values)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial\n",
    "from scipy.special import gammaln\n",
    "\n",
    "def continuous_deformation_of_multinomial_pdf(x, n, p):\n",
    "    if len(x) != len(p):\n",
    "        raise ValueError(\"Length of x and p must be the same!\")\n",
    "    if not np.isclose(sum(x), 1):\n",
    "        return 0\n",
    "    try:\n",
    "        log_numerator = gammaln(n) - gammaln(n - 1)\n",
    "        log_denominator = sum(gammaln((n - 1) * pi) for pi in p)\n",
    "        log_variables_product = 0\n",
    "        for xi, pi in zip(x, p):\n",
    "            if xi > 0:\n",
    "                log_variables_product += ((n - 1) * pi - 1) * np.log(xi)\n",
    "            elif xi == 0 and (n - 1) * pi - 1 < 0:\n",
    "                return 0\n",
    "        log_pmf = log_numerator - log_denominator - log_variables_product\n",
    "        pmf = np.exp(log_pmf)\n",
    "        return pmf\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Input\n",
    "max_n = int(input(\"Enter the maximum number of trials (n): \"))\n",
    "k = 4  # Number of categories\n",
    "\n",
    "# Prepare for plotting\n",
    "n_values = range(1, max_n + 1)\n",
    "continuous_values = []\n",
    "multinomial_values = []\n",
    "\n",
    "for n in n_values:\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    p = np.random.dirichlet(np.ones(k))  # Probability vector of k-th categories\n",
    "    x = np.random.multinomial(n, p)  # Generation of x\n",
    "    \n",
    "    # Ensure x.sum() == n and p.sum() == 1\n",
    "    assert np.isclose(np.sum(x), n), \"x does not sum to n\"\n",
    "    assert np.isclose(np.sum(p), 1), \"p does not sum to 1\"\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    cdf_continuous = continuous_deformation_of_multinomial_pdf(x / n, n, p)\n",
    "    cdf_multinomial = multinomial.pmf(x, n, p)\n",
    "    \n",
    "    continuous_values.append(cdf_continuous)\n",
    "    multinomial_values.append(cdf_multinomial)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_values, continuous_values, label='Continuous Deformation', marker='o')\n",
    "plt.plot(n_values, multinomial_values, label='Multinomial', marker='x')\n",
    "plt.xlabel('Number of Trials (n)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison between Multinomial and Its Continuous Deformation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, max(max(continuous_values), max(multinomial_values)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of Multinomial Distribution and Its Approximations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial, norm, dirichlet, poisson\n",
    "from math import factorial\n",
    "import itertools\n",
    "\n",
    "def edgeworth_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    k = len(probs)\n",
    "    \n",
    "    # Calculate the mean and variance for the normal approximation\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    \n",
    "    # Calculate the standardized counts\n",
    "    z = (counts - mu) / np.sqrt(sigma2)\n",
    "    \n",
    "    # Calculate the skewness and kurtosis\n",
    "    skewness = (1 - 2 * probs) / np.sqrt(sigma2 / n)\n",
    "    kurtosis = (1 - 6 * probs * (1 - probs)) / (sigma2 / n)\n",
    "    \n",
    "    # Calculate the correction terms for Edgeworth expansion\n",
    "    phi_z = norm.pdf(z)\n",
    "    Phi_z = norm.cdf(z)\n",
    "    \n",
    "    term1 = skewness / 6 * (z**3 - 3*z) * phi_z\n",
    "    term2 = kurtosis / 24 * (z**4 - 6*z**2 + 3) * phi_z\n",
    "    term3 = (skewness**2) / 72 * (z**6 - 15*z**4 + 45*z**2 - 15) * phi_z\n",
    "    \n",
    "    correction = Phi_z + term1 + term2 + term3\n",
    "    \n",
    "    # Calculate the multinomial coefficient\n",
    "    multinomial_coeff = factorial(n) / np.prod([factorial(c) for c in counts])\n",
    "    \n",
    "    # Calculate the probability using the normal approximation\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    \n",
    "    # Apply the Edgeworth correction\n",
    "    pmf = multinomial_coeff * normal_approx * np.prod(correction)\n",
    "    \n",
    "    return pmf\n",
    "\n",
    "# Approximation using normal distribution\n",
    "def normal_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    return normal_approx\n",
    "\n",
    "# Approximation using Poisson distribution\n",
    "def poisson_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    lambdas = n * probs\n",
    "    poisson_approx = np.prod([poisson.pmf(counts[i], lambdas[i]) for i in range(len(probs))])\n",
    "    return poisson_approx\n",
    "\n",
    "# MCMC Approximation Function\n",
    "def mcmc_multinomial_pmf(counts, probs, n, num_samples=10000):\n",
    "    counts = np.array(counts)\n",
    "    k = len(probs)\n",
    "    \n",
    "    samples = np.zeros((num_samples, k))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        sample = np.random.multinomial(n, probs)\n",
    "        samples[i] = sample\n",
    "    \n",
    "    sample_pmf = np.mean(np.all(samples == counts, axis=1))\n",
    "    \n",
    "    return sample_pmf\n",
    "\n",
    "# Laplace Approximation Function\n",
    "def laplace_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    k = len(probs)\n",
    "    \n",
    "    # Mean and variance\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    \n",
    "    # Multinomial coefficient\n",
    "    multinomial_coeff = factorial(n) / np.prod([factorial(c) for c in counts])\n",
    "    \n",
    "    # Normal approximation\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    \n",
    "    # Laplace correction\n",
    "    laplace_pmf = multinomial_coeff * normal_approx\n",
    "    \n",
    "    return laplace_pmf\n",
    "\n",
    "'''\n",
    "# Approximation using Dirichlet distribution\n",
    "def dirichlet_multinomial_pmf(counts, alpha):\n",
    "    counts = np.array(counts)\n",
    "    alpha = np.array(alpha)\n",
    "    dirichlet_approx = dirichlet.pdf(counts, alpha)\n",
    "    return dirichlet_approx\n",
    "\n",
    "alpha = np.random.rand(categories) + 1\n",
    "dirichlet_pmfs = [dirichlet_multinomial_pmf(counts, alpha) for counts in counts_list]\n",
    "'''\n",
    "'''\n",
    "# Approximation using Bayesian estimation\n",
    "def bayesian_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    alpha = np.ones_like(probs)\n",
    "    posterior = dirichlet.pdf(probs, alpha + counts)\n",
    "    bayesian_approx = multinomial.pmf(counts, n, probs) * posterior\n",
    "    return bayesian_approx\n",
    "\n",
    "bayesian_pmfs = [bayesian_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "'''\n",
    "\n",
    "def measure_time_and_accuracy(trials, probs, counts_list):\n",
    "    # Calculate exact PMF and measure time\n",
    "    start_time = time.time()\n",
    "    multinomial_pmfs = [multinomial.pmf(counts, n=trials, p=probs) for counts in counts_list]\n",
    "    multinomial_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate approximation PMFs and measure time\n",
    "    start_time = time.time()\n",
    "    edgeworth_pmfs = [edgeworth_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    normal_pmfs = [normal_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    normal_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    poisson_pmfs = [poisson_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    poisson_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mcmc_pmfs = [mcmc_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    mcmc_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    laplace_pmfs = [laplace_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    laplace_time = time.time() - start_time\n",
    "    \n",
    "    # Accuracy measures\n",
    "    def calculate_accuracy(true_pmf, approx_pmf):\n",
    "        return np.mean(np.abs(true_pmf - approx_pmf))\n",
    "    \n",
    "    def calculate_mse(true_pmf, approx_pmf):\n",
    "        return np.mean((true_pmf - approx_pmf) ** 2)\n",
    "    \n",
    "    multinomial_pmf = np.array(multinomial_pmfs)\n",
    "    edgeworth_accuracy = calculate_accuracy(multinomial_pmf, edgeworth_pmfs)\n",
    "    normal_accuracy = calculate_accuracy(multinomial_pmf, normal_pmfs)\n",
    "    poisson_accuracy = calculate_accuracy(multinomial_pmf, poisson_pmfs)\n",
    "    mcmc_accuracy = calculate_accuracy(multinomial_pmf, mcmc_pmfs)\n",
    "    laplace_accuracy = calculate_accuracy(multinomial_pmf, laplace_pmfs)\n",
    "    \n",
    "    edgeworth_mse = calculate_mse(multinomial_pmf, edgeworth_pmfs)\n",
    "    normal_mse = calculate_mse(multinomial_pmf, normal_pmfs)\n",
    "    poisson_mse = calculate_mse(multinomial_pmf, poisson_pmfs)\n",
    "    mcmc_mse = calculate_mse(multinomial_pmf, mcmc_pmfs)\n",
    "    laplace_mse = calculate_mse(multinomial_pmf, laplace_pmfs)\n",
    "    \n",
    "    return (multinomial_pmfs, multinomial_time, \n",
    "            edgeworth_pmfs, edgeworth_time,\n",
    "            normal_pmfs, normal_time,\n",
    "            poisson_pmfs, poisson_time,\n",
    "            mcmc_pmfs, mcmc_time,\n",
    "            laplace_pmfs, laplace_time,\n",
    "            edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy,\n",
    "            edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse)\n",
    "\n",
    "# Parameters and user input\n",
    "categories = 4\n",
    "trials = int(input(\"Number of trials: \"))\n",
    "\n",
    "# Generate random probabilities that sum to 1\n",
    "probs = np.random.rand(categories)\n",
    "probs /= probs.sum()\n",
    "\n",
    "# Generate all possible counts\n",
    "counts_list = list(itertools.product(range(trials + 1), repeat=categories))\n",
    "counts_list = [counts for counts in counts_list if sum(counts) == trials]\n",
    "\n",
    "'''\n",
    "# Calculate PMFs\n",
    "multinomial_pmfs = [multinomial.pmf(counts, n=trials, p=probs) for counts in counts_list]\n",
    "edgeworth_pmfs = [edgeworth_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "normal_pmfs = [normal_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "poisson_pmfs = [poisson_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "mcmc_pmfs = [mcmc_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "laplace_pmfs = [laplace_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "'''\n",
    "\n",
    "# Measure time and accuracy\n",
    "results = measure_time_and_accuracy(trials, probs, counts_list)\n",
    "(multinomial_pmfs, multinomial_time, \n",
    " edgeworth_pmfs, edgeworth_time,\n",
    " normal_pmfs, normal_time,\n",
    " poisson_pmfs, poisson_time,\n",
    " mcmc_pmfs, mcmc_time,\n",
    " laplace_pmfs, laplace_time,\n",
    " edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy,\n",
    " edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse) = results\n",
    "\n",
    "# Plotting\n",
    "#labels = [str(counts) for counts in counts_list]\n",
    "#x = np.arange(len(counts_list))\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Probability mass functions comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "x = np.arange(len(counts_list))\n",
    "plt.plot(x, multinomial_pmfs, marker='o', linestyle='-', label='True Multinomial')\n",
    "plt.plot(x, edgeworth_pmfs, marker='x', linestyle='-', label='Edgeworth Approximation')\n",
    "plt.plot(x, normal_pmfs, marker='v', linestyle='-', label='Normal Approximation')\n",
    "plt.plot(x, poisson_pmfs, marker='s', linestyle='-', label='Poisson Approximation')\n",
    "plt.plot(x, mcmc_pmfs, marker='D', linestyle='-', label='MCMC Approximation')\n",
    "plt.plot(x, laplace_pmfs, marker='^', linestyle='-', label='Laplace Approximation')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('PMF')\n",
    "plt.title('Probability Mass Functions Comparison')\n",
    "#plt.xticks(x, [str(counts) for counts in counts_list], rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "# Execution time comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Multinomial', 'Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "times = [multinomial_time, edgeworth_time, normal_time, poisson_time, mcmc_time, laplace_time]\n",
    "plt.bar(methods, times, color=['black', 'red', 'blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "accuracies = [edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy]\n",
    "plt.bar(methods, accuracies, color=['red', 'blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Mean Absolute Error Comparison')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "mses = [edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse]\n",
    "plt.bar(methods, mses, color=['red', 'blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Mean Squared Error Comparison')\n",
    "\n",
    "#plt.suptitle(f'Comparison of Multinomial Distribution and Its Approximations (Number of trials: {trials})', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of Multinomial Distribution and Its Approximations with logarithmic vertical axis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial, norm, dirichlet, poisson\n",
    "from math import factorial\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "def edgeworth_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    k = len(probs)\n",
    "    \n",
    "    # Calculate the mean and variance for the normal approximation\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    \n",
    "    # Calculate the standardized counts\n",
    "    z = (counts - mu) / np.sqrt(sigma2)\n",
    "    \n",
    "    # Calculate the skewness and kurtosis\n",
    "    skewness = (1 - 2 * probs) / np.sqrt(sigma2 / n)\n",
    "    kurtosis = (1 - 6 * probs * (1 - probs)) / (sigma2 / n)\n",
    "    \n",
    "    # Calculate the correction terms for Edgeworth expansion\n",
    "    phi_z = norm.pdf(z)\n",
    "    Phi_z = norm.cdf(z)\n",
    "    \n",
    "    term1 = skewness / 6 * (z**3 - 3*z) * phi_z\n",
    "    term2 = kurtosis / 24 * (z**4 - 6*z**2 + 3) * phi_z\n",
    "    term3 = (skewness**2) / 72 * (z**6 - 15*z**4 + 45*z**2 - 15) * phi_z\n",
    "    \n",
    "    correction = Phi_z + term1 + term2 + term3\n",
    "    \n",
    "    # Calculate the multinomial coefficient\n",
    "    multinomial_coeff = factorial(n) / np.prod([factorial(c) for c in counts])\n",
    "    \n",
    "    # Calculate the probability using the normal approximation\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    \n",
    "    # Apply the Edgeworth correction\n",
    "    pmf = multinomial_coeff * normal_approx * np.prod(correction)\n",
    "    \n",
    "    return pmf\n",
    "\n",
    "# Approximation using normal distribution\n",
    "def normal_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    return normal_approx\n",
    "\n",
    "# Approximation using Poisson distribution\n",
    "def poisson_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    lambdas = n * probs\n",
    "    poisson_approx = np.prod([poisson.pmf(counts[i], lambdas[i]) for i in range(len(probs))])\n",
    "    return poisson_approx\n",
    "\n",
    "# MCMC Approximation Function\n",
    "def mcmc_multinomial_pmf(counts, probs, n, num_samples=10000):\n",
    "    counts = np.array(counts)\n",
    "    k = len(probs)\n",
    "    \n",
    "    samples = np.zeros((num_samples, k))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        sample = np.random.multinomial(n, probs)\n",
    "        samples[i] = sample\n",
    "    \n",
    "    sample_pmf = np.mean(np.all(samples == counts, axis=1))\n",
    "    \n",
    "    return sample_pmf\n",
    "\n",
    "# Laplace Approximation Function\n",
    "def laplace_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    k = len(probs)\n",
    "    \n",
    "    # Mean and variance\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    \n",
    "    # Multinomial coefficient\n",
    "    multinomial_coeff = factorial(n) / np.prod([factorial(c) for c in counts])\n",
    "    \n",
    "    # Normal approximation\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    \n",
    "    # Laplace correction\n",
    "    laplace_pmf = multinomial_coeff * normal_approx\n",
    "    \n",
    "    return laplace_pmf\n",
    "\n",
    "def measure_time_and_accuracy(trials, probs, counts_list):\n",
    "    # Calculate exact PMF and measure time\n",
    "    start_time = time.time()\n",
    "    multinomial_pmfs = [multinomial.pmf(counts, n=trials, p=probs) for counts in counts_list]\n",
    "    multinomial_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate approximation PMFs and measure time\n",
    "    start_time = time.time()\n",
    "    edgeworth_pmfs = [edgeworth_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    normal_pmfs = [normal_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    normal_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    poisson_pmfs = [poisson_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    poisson_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mcmc_pmfs = [mcmc_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    mcmc_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    laplace_pmfs = [laplace_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    laplace_time = time.time() - start_time\n",
    "    \n",
    "    # Accuracy measures\n",
    "    def calculate_accuracy(true_pmf, approx_pmf):\n",
    "        return np.mean(np.abs(true_pmf - approx_pmf))\n",
    "    \n",
    "    def calculate_mse(true_pmf, approx_pmf):\n",
    "        return np.mean((true_pmf - approx_pmf) ** 2)\n",
    "    \n",
    "    multinomial_pmf = np.array(multinomial_pmfs)\n",
    "    edgeworth_accuracy = calculate_accuracy(multinomial_pmf, edgeworth_pmfs)\n",
    "    normal_accuracy = calculate_accuracy(multinomial_pmf, normal_pmfs)\n",
    "    poisson_accuracy = calculate_accuracy(multinomial_pmf, poisson_pmfs)\n",
    "    mcmc_accuracy = calculate_accuracy(multinomial_pmf, mcmc_pmfs)\n",
    "    laplace_accuracy = calculate_accuracy(multinomial_pmf, laplace_pmfs)\n",
    "    \n",
    "    edgeworth_mse = calculate_mse(multinomial_pmf, edgeworth_pmfs)\n",
    "    normal_mse = calculate_mse(multinomial_pmf, normal_pmfs)\n",
    "    poisson_mse = calculate_mse(multinomial_pmf, poisson_pmfs)\n",
    "    mcmc_mse = calculate_mse(multinomial_pmf, mcmc_pmfs)\n",
    "    laplace_mse = calculate_mse(multinomial_pmf, laplace_pmfs)\n",
    "    \n",
    "    return (multinomial_pmfs, multinomial_time, \n",
    "            edgeworth_pmfs, edgeworth_time,\n",
    "            normal_pmfs, normal_time,\n",
    "            poisson_pmfs, poisson_time,\n",
    "            mcmc_pmfs, mcmc_time,\n",
    "            laplace_pmfs, laplace_time,\n",
    "            edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy,\n",
    "            edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse)\n",
    "\n",
    "# Parameters and user input\n",
    "categories = 4\n",
    "trials = int(input(\"Number of trials: \"))\n",
    "\n",
    "# Generate random probabilities that sum to 1\n",
    "probs = np.random.rand(categories)\n",
    "probs /= probs.sum()\n",
    "\n",
    "# Generate all possible counts\n",
    "counts_list = list(itertools.product(range(trials + 1), repeat=categories))\n",
    "counts_list = [counts for counts in counts_list if sum(counts) == trials]\n",
    "\n",
    "# Measure time and accuracy\n",
    "results = measure_time_and_accuracy(trials, probs, counts_list)\n",
    "(multinomial_pmfs, multinomial_time, \n",
    " edgeworth_pmfs, edgeworth_time,\n",
    " normal_pmfs, normal_time,\n",
    " poisson_pmfs, poisson_time,\n",
    " mcmc_pmfs, mcmc_time,\n",
    " laplace_pmfs, laplace_time,\n",
    " edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy,\n",
    " edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse) = results\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Probability mass functions comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "x = np.arange(len(counts_list))\n",
    "plt.plot(x, multinomial_pmfs, marker='o', linestyle='-', label='True Multinomial')\n",
    "plt.plot(x, edgeworth_pmfs, marker='x', linestyle='-', label='Edgeworth Approximation')\n",
    "plt.plot(x, normal_pmfs, marker='v', linestyle='-', label='Normal Approximation')\n",
    "plt.plot(x, poisson_pmfs, marker='s', linestyle='-', label='Poisson Approximation')\n",
    "plt.plot(x, mcmc_pmfs, marker='D', linestyle='-', label='MCMC Approximation')\n",
    "plt.plot(x, laplace_pmfs, marker='^', linestyle='-', label='Laplace Approximation')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('ln(PMF)')\n",
    "plt.title('Probability Mass Functions Comparison with logarithm')\n",
    "plt.yscale('log')  # Seting the y-axis to logarithmic scale\n",
    "plt.legend()\n",
    "\n",
    "# Execution time comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Multinomial', 'Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "times = [multinomial_time, edgeworth_time, normal_time, poisson_time, mcmc_time, laplace_time]\n",
    "plt.bar(methods, times, color=['black', 'red', 'blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "accuracies = [edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy]\n",
    "plt.bar(methods, accuracies, color=['red', 'blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Mean Absolute Error Comparison')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "mses = [edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse]\n",
    "plt.bar(methods, mses, color=['red', 'blue', 'orange', 'green', 'purple'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Mean Squared Error Comparison')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of Multinomial Distribution and Its Approximations (with logarithmic vertical axis)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multinomial, norm, dirichlet, poisson\n",
    "from math import factorial\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "def edgeworth_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    k = len(probs)\n",
    "    \n",
    "    # Calculate the mean and variance for the normal approximation\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    \n",
    "    # Calculate the standardized counts\n",
    "    z = (counts - mu) / np.sqrt(sigma2)\n",
    "    \n",
    "    # Calculate the skewness and kurtosis\n",
    "    skewness = (1 - 2 * probs) / np.sqrt(sigma2 / n)\n",
    "    kurtosis = (1 - 6 * probs * (1 - probs)) / (sigma2 / n)\n",
    "    \n",
    "    # Calculate the correction terms for Edgeworth expansion\n",
    "    phi_z = norm.pdf(z)\n",
    "    Phi_z = norm.cdf(z)\n",
    "    \n",
    "    term1 = skewness / 6 * (z**3 - 3*z) * phi_z\n",
    "    term2 = kurtosis / 24 * (z**4 - 6*z**2 + 3) * phi_z\n",
    "    term3 = (skewness**2) / 72 * (z**6 - 15*z**4 + 45*z**2 - 15) * phi_z\n",
    "    \n",
    "    correction = Phi_z + term1 + term2 + term3\n",
    "    \n",
    "    # Calculate the multinomial coefficient\n",
    "    multinomial_coeff = factorial(n) / np.prod([factorial(c) for c in counts])\n",
    "    \n",
    "    # Calculate the probability using the normal approximation\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    \n",
    "    # Apply the Edgeworth correction\n",
    "    pmf = multinomial_coeff * normal_approx * np.prod(correction)\n",
    "    \n",
    "    return pmf\n",
    "\n",
    "# Approximation using normal distribution\n",
    "def normal_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    return normal_approx\n",
    "\n",
    "# Approximation using Poisson distribution\n",
    "def poisson_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    lambdas = n * probs\n",
    "    poisson_approx = np.prod([poisson.pmf(counts[i], lambdas[i]) for i in range(len(probs))])\n",
    "    return poisson_approx\n",
    "\n",
    "# MCMC Approximation Function\n",
    "def mcmc_multinomial_pmf(counts, probs, n, num_samples=10000):\n",
    "    counts = np.array(counts)\n",
    "    k = len(probs)\n",
    "    \n",
    "    samples = np.zeros((num_samples, k))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        sample = np.random.multinomial(n, probs)\n",
    "        samples[i] = sample\n",
    "    \n",
    "    sample_pmf = np.mean(np.all(samples == counts, axis=1))\n",
    "    \n",
    "    return sample_pmf\n",
    "\n",
    "# Laplace Approximation Function\n",
    "def laplace_multinomial_pmf(counts, probs, n):\n",
    "    counts = np.array(counts)\n",
    "    probs = np.array(probs)\n",
    "    k = len(probs)\n",
    "    \n",
    "    # Mean and variance\n",
    "    mu = n * probs\n",
    "    sigma2 = n * probs * (1 - probs)\n",
    "    \n",
    "    # Multinomial coefficient\n",
    "    multinomial_coeff = factorial(n) / np.prod([factorial(c) for c in counts])\n",
    "    \n",
    "    # Normal approximation\n",
    "    normal_approx = np.prod(norm.pdf((counts - mu) / np.sqrt(sigma2)))\n",
    "    \n",
    "    # Laplace correction\n",
    "    laplace_pmf = multinomial_coeff * normal_approx\n",
    "    \n",
    "    return laplace_pmf\n",
    "\n",
    "def measure_time_and_accuracy(trials, probs, counts_list):\n",
    "    # Calculate exact PMF and measure time\n",
    "    start_time = time.time()\n",
    "    multinomial_pmfs = [multinomial.pmf(counts, n=trials, p=probs) for counts in counts_list]\n",
    "    multinomial_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate approximation PMFs and measure time\n",
    "    start_time = time.time()\n",
    "    edgeworth_pmfs = [edgeworth_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    normal_pmfs = [normal_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    normal_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    poisson_pmfs = [poisson_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    poisson_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mcmc_pmfs = [mcmc_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    mcmc_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    laplace_pmfs = [laplace_multinomial_pmf(counts, probs, trials) for counts in counts_list]\n",
    "    laplace_time = time.time() - start_time\n",
    "    \n",
    "    # Accuracy measures\n",
    "    def calculate_accuracy(true_pmf, approx_pmf):\n",
    "        return np.mean(np.abs(true_pmf - approx_pmf))\n",
    "    \n",
    "    def calculate_mse(true_pmf, approx_pmf):\n",
    "        return np.mean((true_pmf - approx_pmf) ** 2)\n",
    "    \n",
    "    multinomial_pmf = np.array(multinomial_pmfs)\n",
    "    edgeworth_accuracy = calculate_accuracy(multinomial_pmf, edgeworth_pmfs)\n",
    "    normal_accuracy = calculate_accuracy(multinomial_pmf, normal_pmfs)\n",
    "    poisson_accuracy = calculate_accuracy(multinomial_pmf, poisson_pmfs)\n",
    "    mcmc_accuracy = calculate_accuracy(multinomial_pmf, mcmc_pmfs)\n",
    "    laplace_accuracy = calculate_accuracy(multinomial_pmf, laplace_pmfs)\n",
    "    \n",
    "    edgeworth_mse = calculate_mse(multinomial_pmf, edgeworth_pmfs)\n",
    "    normal_mse = calculate_mse(multinomial_pmf, normal_pmfs)\n",
    "    poisson_mse = calculate_mse(multinomial_pmf, poisson_pmfs)\n",
    "    mcmc_mse = calculate_mse(multinomial_pmf, mcmc_pmfs)\n",
    "    laplace_mse = calculate_mse(multinomial_pmf, laplace_pmfs)\n",
    "    \n",
    "    return (multinomial_pmfs, multinomial_time, \n",
    "            edgeworth_pmfs, edgeworth_time,\n",
    "            normal_pmfs, normal_time,\n",
    "            poisson_pmfs, poisson_time,\n",
    "            mcmc_pmfs, mcmc_time,\n",
    "            laplace_pmfs, laplace_time,\n",
    "            edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy,\n",
    "            edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse)\n",
    "\n",
    "# Parameters and user input\n",
    "categories = 4\n",
    "trials = int(input(\"Number of trials: \"))\n",
    "\n",
    "# Generate random probabilities that sum to 1\n",
    "probs = np.random.rand(categories)\n",
    "probs /= probs.sum()\n",
    "\n",
    "# Generate all possible counts\n",
    "counts_list = list(itertools.product(range(trials + 1), repeat=categories))\n",
    "counts_list = [counts for counts in counts_list if sum(counts) == trials]\n",
    "\n",
    "# Measure time and accuracy\n",
    "results = measure_time_and_accuracy(trials, probs, counts_list)\n",
    "(multinomial_pmfs, multinomial_time, \n",
    " edgeworth_pmfs, edgeworth_time,\n",
    " normal_pmfs, normal_time,\n",
    " poisson_pmfs, poisson_time,\n",
    " mcmc_pmfs, mcmc_time,\n",
    " laplace_pmfs, laplace_time,\n",
    " edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy,\n",
    " edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse) = results\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Colors and markers for consistency\n",
    "colors = ['black', 'red', 'blue', 'orange', 'green', 'purple']\n",
    "markers = ['o', 'x', 'v', 's', 'D', '^']\n",
    "labels = ['True Multinomial', 'Edgeworth Approximation', 'Normal Approximation', 'Poisson Approximation', 'MCMC Approximation', 'Laplace Approximation']\n",
    "\n",
    "# Probability mass functions comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "x = np.arange(len(counts_list))\n",
    "plt.plot(x, np.log10(multinomial_pmfs), marker=markers[0], linestyle='-', color=colors[0], label=labels[0])\n",
    "plt.plot(x, np.log10(edgeworth_pmfs), marker=markers[1], linestyle='-', color=colors[1], label=labels[1])\n",
    "plt.plot(x, np.log10(normal_pmfs), marker=markers[2], linestyle='-', color=colors[2], label=labels[2])\n",
    "plt.plot(x, np.log10(poisson_pmfs), marker=markers[3], linestyle='-', color=colors[3], label=labels[3])\n",
    "plt.plot(x, np.log10(mcmc_pmfs), marker=markers[4], linestyle='-', color=colors[4], label=labels[4])\n",
    "plt.plot(x, np.log10(laplace_pmfs), marker=markers[5], linestyle='-', color=colors[5], label=labels[5])\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('log10(PMF)')\n",
    "plt.title('Probability Mass Functions Comparison with logarithm')\n",
    "#plt.xticks(x, [str(counts) for counts in counts_list], rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "# Execution time comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Multinomial', 'Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "times = [multinomial_time, edgeworth_time, normal_time, poisson_time, mcmc_time, laplace_time]\n",
    "plt.bar(methods, times, color=colors)\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "accuracies = [edgeworth_accuracy, normal_accuracy, poisson_accuracy, mcmc_accuracy, laplace_accuracy]\n",
    "plt.bar(methods, accuracies, color=colors[1:])  # Adjust colors to match methods\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Absolute Error (common logarithm)')\n",
    "plt.title('Mean Absolute Error Comparison')\n",
    "plt.yscale('log', base=10)  # Setting the y-axis to logarithmic scale with base 10\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Edgeworth', 'Normal', 'Poisson', 'MCMC', 'Laplace']\n",
    "mses = [edgeworth_mse, normal_mse, poisson_mse, mcmc_mse, laplace_mse]\n",
    "plt.bar(methods, mses, color=colors[1:])  # Adjust colors to match methods\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Mean Squared Error (common logarithm)')\n",
    "plt.title('Mean Squared Error Comparison')\n",
    "plt.yscale('log', base=10)  # Setting the y-axis to logarithmic scale with base 10\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of Binomial Distribution and Its Approximations (with logarithmic vertical axis)\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "n = int(input(\"n = \"))\n",
    "p = float(input(\"The probability is \"))\n",
    "\n",
    "# The binomial distribution\n",
    "binom_rv = stats.binom(n, p)\n",
    "x = np.arange(0, n + 1)\n",
    "binom_pmf = binom_rv.pmf(x)\n",
    "\n",
    "# Normal approximation\n",
    "mu = n * p\n",
    "sigma = np.sqrt(n * p * (1 - p))\n",
    "norm_rv = stats.norm(mu, sigma)\n",
    "norm_pmf = norm_rv.pdf(x)\n",
    "\n",
    "# Continuous normal distribution\n",
    "continuous_norm_rv = stats.norm(mu, sigma)\n",
    "continuous_x = np.linspace(-n, n, 100)  \n",
    "continuous_norm_pmf = continuous_norm_rv.pdf(continuous_x)\n",
    "\n",
    "# Poisson approximation\n",
    "lambda_ = n * p\n",
    "poisson_rv = stats.poisson(lambda_)\n",
    "poisson_pmf = poisson_rv.pmf(x)\n",
    "\n",
    "# Edgeworth expansion\n",
    "def edgeworth_expansion(x, n, p):\n",
    "    q = 1 - p\n",
    "    mu = n * p\n",
    "    sigma = np.sqrt(n * p * q)\n",
    "    z = (x - mu) / sigma\n",
    "    skewness = (q - p) / np.sqrt(n * p * q)\n",
    "    kurtosis = (1 - 6*p*q) / (n * p * q)\n",
    "\n",
    "    phi_z = stats.norm.pdf(z)\n",
    "    Phi_z = stats.norm.cdf(z)\n",
    "\n",
    "    correction = (1/6) * skewness * (z**2 - 1) * phi_z + (1/24) * kurtosis * (z**3 - 3*z) * phi_z - (1/36) * skewness**2 * (z**5 - 10*z**3 + 15*z) * phi_z\n",
    "\n",
    "    return Phi_z + correction\n",
    "\n",
    "# Measuring execution time for each approximation\n",
    "def measure_time_and_accuracy():    \n",
    "    start_time = time.time()\n",
    "    binom_rv = stats.binom(n, p)\n",
    "    binom_pmf = binom_rv.pmf(x)\n",
    "    binom_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    norm_rv = stats.norm(mu, sigma)\n",
    "    norm_pmf = norm_rv.pdf(x)\n",
    "    norm_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    poisson_rv = stats.poisson(lambda_)\n",
    "    poisson_pmf = poisson_rv.pmf(x)\n",
    "    poisson_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    edgeworth_cdf = edgeworth_expansion(x, n, p)\n",
    "    edgeworth_pmf = np.diff(edgeworth_cdf, prepend=0)\n",
    "    edgeworth_time = time.time() - start_time\n",
    "    \n",
    "    return binom_pmf, binom_time, norm_pmf, norm_time, poisson_pmf, poisson_time, edgeworth_pmf, edgeworth_time\n",
    "\n",
    "binom_pmf, binom_time, norm_pmf, norm_time, poisson_pmf, poisson_time, edgeworth_pmf, edgeworth_time = measure_time_and_accuracy()\n",
    "\n",
    "# Accuracy measures\n",
    "def calculate_accuracy(true_pmf, approx_pmf):\n",
    "    return np.mean(np.abs(true_pmf - approx_pmf))\n",
    "def calculate_mse(true_pmf, approx_pmf):\n",
    "    return np.mean((true_pmf - approx_pmf) ** 2)\n",
    "\n",
    "binom_accuracy = calculate_accuracy(binom_pmf, binom_pmf)\n",
    "norm_accuracy = calculate_accuracy(binom_pmf, norm_pmf)\n",
    "poisson_accuracy = calculate_accuracy(binom_pmf, poisson_pmf)\n",
    "edgeworth_accuracy = calculate_accuracy(binom_pmf, edgeworth_pmf)\n",
    "binom_mse = calculate_mse(binom_pmf, binom_pmf)\n",
    "norm_mse = calculate_mse(binom_pmf, norm_pmf)\n",
    "poisson_mse = calculate_mse(binom_pmf, poisson_pmf)\n",
    "edgeworth_mse = calculate_mse(binom_pmf, edgeworth_pmf)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Probability mass functions comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(x, binom_pmf, alpha=0.5, label='Binomial distribution', color='black')\n",
    "plt.plot(x, norm_pmf, label='Normal approximation')\n",
    "plt.plot(continuous_x, continuous_norm_pmf, 'r--', label='Continuous Normal')\n",
    "plt.plot(x, poisson_pmf, label='Poisson approximation')\n",
    "plt.plot(x, edgeworth_pmf, label='Edgeworth approximation')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability Mass Functions Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Execution time comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "methods = ['Binomial', 'Normal', 'Poisson', 'Edgeworth']\n",
    "times = [binom_time, norm_time, poisson_time, edgeworth_time]\n",
    "plt.bar(methods, times, color=['black', 'blue', 'orange', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Execution Time Comparison')\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "methods = ['Normal', 'Poisson', 'Edgeworth']\n",
    "accuracies = [norm_accuracy, poisson_accuracy, edgeworth_accuracy]\n",
    "plt.bar(methods, accuracies, color=['blue', 'orange', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('log10(MAE)') #Mean Absolute Error\n",
    "plt.yscale('log', base=10)\n",
    "plt.title('Accuracy Comparison 1')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Normal', 'Poisson', 'Edgeworth']\n",
    "mses = [norm_mse, poisson_mse, edgeworth_mse]\n",
    "plt.bar(methods, mses, color=['blue', 'orange', 'green'])\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('log10(MSE)') #Mean Squared Error\n",
    "plt.yscale('log', base=10)\n",
    "plt.title('Accuracy Comparison 2')\n",
    "\n",
    "#plt.suptitle('Comparison of Binomial Distribution and Its Approximations (Number of trials: '+str(n)+', probability: '+str(p)+')', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qokit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
