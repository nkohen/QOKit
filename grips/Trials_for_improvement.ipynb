{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improvement in progress\n",
    "import numpy as np\n",
    "import math\n",
    "import typing\n",
    "import time\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import multinomial#, binom\n",
    "\n",
    "# Edgeworth expansion approximation\n",
    "def edgeworth_expansion(x, n, p):\n",
    "    q = 1 - p\n",
    "    mu = n * p\n",
    "    sigma = np.sqrt(n * p * q)\n",
    "    z = (x - mu) / sigma\n",
    "    skewness = (q - p) / np.sqrt(n * p * q)\n",
    "    kurtosis = (1 - 6*p*q) / (n * p * q)\n",
    "\n",
    "    phi_z = stats.norm.pdf(z)\n",
    "    Phi_z = stats.norm.cdf(z)\n",
    "\n",
    "    correction = (1/6) * skewness * (z**2 - 1) * phi_z + (1/24) * kurtosis * (z**3 - 3*z) * phi_z - (1/36) * skewness**2 * (z**5 - 10*z**3 + 15*z) * phi_z\n",
    "\n",
    "    return Phi_z + correction\n",
    "\n",
    "# P(c') with the approximation\n",
    "def prob_cost_imp(cost: int, num_constraints: int, prob_edge: float = 0.5) -> float:\n",
    "    #return binom.pmf(cost, num_constraints, prob_edge)\n",
    "    #edgeworth_cdf = edgeworth_expansion(cost, num_constraints, prob_edge)\n",
    "    #return np.diff(edgeworth_cdf, prepend=0) # edgeworth_pmf\n",
    "    x = np.arange(num_constraints + 1)\n",
    "    edgeworth_values = edgeworth_expansion(x, num_constraints, prob_edge)\n",
    "    # Use np.diff to compute the difference\n",
    "    edgeworth_pmf = np.diff(edgeworth_values, prepend=0)\n",
    "    return edgeworth_pmf[cost]\n",
    "\n",
    "# N(c') from paper\n",
    "def number_with_cost_imp_proxy(cost: int, num_constraints: int, num_qubits: int, prob_edge: float = 0.5) -> float:\n",
    "    scale = 1 << num_qubits\n",
    "    return prob_cost_imp(cost, num_constraints, prob_edge) * scale\n",
    "\n",
    "# P(b, c'-b, c-b | d) from paper\n",
    "def prob_common_at_distance_imp(num_constraints: int, common_constraints: int, cost_1: int, cost_2: int, distance: int) -> float:\n",
    "    prob_same = (math.comb(num_constraints - distance, 2) + math.comb(distance, 2)) / math.comb(num_constraints, 2)\n",
    "    prob_neither = prob_same / 2\n",
    "    prob_both = prob_neither\n",
    "    prob_one = (1 - prob_neither - prob_both) / 2\n",
    "    return multinomial.pmf(\n",
    "        [common_constraints, cost_1 - common_constraints, cost_2 - common_constraints, num_constraints + common_constraints - (cost_1 + cost_2)],\n",
    "        num_constraints,\n",
    "        [prob_both, prob_one, prob_one, prob_neither],\n",
    "    )\n",
    "\n",
    "# N(c'; d, c) from paper\n",
    "def number_of_costs_at_distance_imp_proxy(cost_1: int, cost_2: int, distance: int, num_constraints: int, num_qubits: int, prob_edge: float = 0.5) -> float:\n",
    "    sum = 0\n",
    "    for common_constraints in range(max(0, cost_1 + cost_2 - num_constraints), min(cost_1, cost_2) + 1):\n",
    "        sum += prob_common_at_distance_imp(num_constraints, common_constraints, cost_1, cost_2, distance)\n",
    "\n",
    "    p_cost = prob_cost_imp(cost_1, num_constraints, prob_edge)\n",
    "    return (math.comb(num_qubits, distance) / p_cost) * sum\n",
    "\n",
    "# Computes the sum inside the for loop of Algorithm 1 in paper\n",
    "def compute_amplitude_sum_imp(prev_amplitudes: np.ndarray, gamma: float, beta: float, cost_1: int, num_constraints: int, num_qubits: int) -> complex:\n",
    "    sum = 0\n",
    "    for cost_2 in range(num_constraints + 1):\n",
    "        for distance in range(num_qubits + 1):\n",
    "            # Should I np-ify all of the stuff here?\n",
    "            beta_factor = (np.cos(beta) ** (num_qubits - distance)) * ((-1j * np.sin(beta)) ** distance)\n",
    "            gamma_factor = np.exp(-1j * gamma * cost_2)\n",
    "            num_costs_at_distance = number_of_costs_at_distance_imp_proxy(cost_1, cost_2, distance, num_constraints, num_qubits)\n",
    "            sum += beta_factor * gamma_factor * prev_amplitudes[cost_2] * num_costs_at_distance\n",
    "    return sum\n",
    "\n",
    "# TODO: What if instead of optimizing expectation proxy we instead optimize high cost amplitudes (using e.g. exponential weighting)\n",
    "# Algorithm 1 from paper\n",
    "# num_constraints = number of edges, and num_qubits = number of vertices\n",
    "def QAOA_imp_proxy(p: int, gamma: np.ndarray, beta: np.ndarray, num_constraints: int, num_qubits: int):\n",
    "    num_costs = num_constraints + 1\n",
    "    amplitude_proxies = np.zeros([p + 1, num_costs], dtype=complex)\n",
    "    init_amplitude = np.sqrt(1 / (1 << num_qubits))\n",
    "    for i in range(num_costs):\n",
    "        amplitude_proxies[0][i] = init_amplitude\n",
    "\n",
    "    for current_depth in range(1, p + 1):\n",
    "        for cost_1 in range(num_costs):\n",
    "            amplitude_proxies[current_depth][cost_1] = compute_amplitude_sum_imp(\n",
    "                amplitude_proxies[current_depth - 1], gamma[current_depth - 1], beta[current_depth - 1], cost_1, num_constraints, num_qubits\n",
    "            )\n",
    "\n",
    "    expected_proxy = 0\n",
    "    for cost in range(num_costs):\n",
    "        expected_proxy += number_with_cost_imp_proxy(cost, num_constraints, num_qubits) * (abs(amplitude_proxies[p][cost]) ** 2) * cost\n",
    "\n",
    "    return amplitude_proxies, expected_proxy\n",
    "\n",
    "def inverse_imp_proxy_objective_function(num_constraints: int, num_qubits: int, p: int, expectations: list[np.ndarray] | None) -> typing.Callable:\n",
    "    def inverse_objective(*args) -> float:\n",
    "        gamma, beta = args[0][:p], args[0][p:]\n",
    "        _, expectation = QAOA_imp_proxy(p, gamma, beta, num_constraints, num_qubits)\n",
    "        current_time = time.time()\n",
    "\n",
    "        if expectations is not None:\n",
    "            expectations.append((current_time, expectation))\n",
    "\n",
    "        return -expectation\n",
    "\n",
    "    return inverse_objective\n",
    "\n",
    "def QAOA_imp_proxy_run(\n",
    "    num_constraints: int,\n",
    "    num_qubits: int,\n",
    "    p: int,\n",
    "    init_gamma: np.ndarray,\n",
    "    init_beta: np.ndarray,\n",
    "    optimizer_method: str = \"COBYLA\",\n",
    "    optimizer_options: dict | None = None,\n",
    "    expectations: list[np.ndarray] | None = None,\n",
    ") -> dict:\n",
    "    init_freq = np.hstack([init_gamma, init_beta])\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = scipy.optimize.minimize(\n",
    "        inverse_imp_proxy_objective_function(num_constraints, num_qubits, p, expectations),\n",
    "        init_freq,\n",
    "        args=(),\n",
    "        method=optimizer_method,\n",
    "        options=optimizer_options,\n",
    "    )\n",
    "    # the above returns a scipy optimization result object that has multiple attributes\n",
    "    # result.x gives the optimal solutionsol.success #bool whether algorithm succeeded\n",
    "    # result.message #message of why algorithms terminated\n",
    "    # result.nfev is number of iterations used (here, number of QAOA calls)\n",
    "    end_time = time.time()\n",
    "\n",
    "    def make_time_relative(input: tuple[float, float]) -> tuple[float, float]:\n",
    "        time, x = input\n",
    "        return (time - start_time, x)\n",
    "\n",
    "    if expectations is not None:\n",
    "        expectations = list(map(make_time_relative, expectations))\n",
    "\n",
    "    gamma, beta = result.x[:p], result.x[p:]\n",
    "    _, expectation = QAOA_imp_proxy(p, gamma, beta, num_constraints, num_qubits)\n",
    "\n",
    "    return {\n",
    "        \"gamma\": gamma,\n",
    "        \"beta\": beta,\n",
    "        \"expectation\": expectation,\n",
    "        \"runtime\": end_time - start_time,  # measured in seconds\n",
    "        \"num_QAOA_calls\": result.nfev,  # Calls to the proxy of course\n",
    "        \"classical_opt_success\": result.success,\n",
    "        \"scipy_opt_message\": result.message,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QAOA_paper_proxy\n",
    "import numpy as np\n",
    "import math\n",
    "import typing\n",
    "import time\n",
    "import scipy\n",
    "from scipy.stats import binom, multinomial\n",
    "\n",
    "\"\"\"\n",
    "This file implements the QAOA proxy algorithm for MaxCut from:\n",
    "https://journals.aps.org/prresearch/pdf/10.1103/PhysRevResearch.6.023171\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# P(c') from paper\n",
    "def prob_cost_paper(cost: int, num_constraints: int, prob_edge: float = 0.5) -> float:\n",
    "    return binom.pmf(cost, num_constraints, prob_edge)\n",
    "\n",
    "\n",
    "# N(c') from paper\n",
    "def number_with_cost_paper_proxy(cost: int, num_constraints: int, num_qubits: int, prob_edge: float = 0.5) -> float:\n",
    "    scale = 1 << num_qubits\n",
    "    return prob_cost_paper(cost, num_constraints, prob_edge) * scale\n",
    "\n",
    "\n",
    "# P(b, c'-b, c-b | d) from paper\n",
    "def prob_common_at_distance_paper(num_constraints: int, common_constraints: int, cost_1: int, cost_2: int, distance: int) -> float:\n",
    "    prob_same = (math.comb(num_constraints - distance, 2) + math.comb(distance, 2)) / math.comb(num_constraints, 2)\n",
    "    prob_neither = prob_same / 2\n",
    "    prob_both = prob_neither\n",
    "    prob_one = (1 - prob_neither - prob_both) / 2\n",
    "    return multinomial.pmf(\n",
    "        [common_constraints, cost_1 - common_constraints, cost_2 - common_constraints, num_constraints + common_constraints - (cost_1 + cost_2)],\n",
    "        num_constraints,\n",
    "        [prob_both, prob_one, prob_one, prob_neither],\n",
    "    )\n",
    "\n",
    "\n",
    "# N(c'; d, c) from paper\n",
    "def number_of_costs_at_distance_paper_proxy(cost_1: int, cost_2: int, distance: int, num_constraints: int, num_qubits: int, prob_edge: float = 0.5) -> float:\n",
    "    sum = 0\n",
    "    for common_constraints in range(max(0, cost_1 + cost_2 - num_constraints), min(cost_1, cost_2) + 1):\n",
    "        sum += prob_common_at_distance_paper(num_constraints, common_constraints, cost_1, cost_2, distance)\n",
    "\n",
    "    p_cost = prob_cost_paper(cost_1, num_constraints, prob_edge)\n",
    "    return (math.comb(num_qubits, distance) / p_cost) * sum\n",
    "\n",
    "\n",
    "# Computes the sum inside the for loop of Algorithm 1 in paper\n",
    "def compute_amplitude_sum_paper(prev_amplitudes: np.ndarray, gamma: float, beta: float, cost_1: int, num_constraints: int, num_qubits: int) -> complex:\n",
    "    sum = 0\n",
    "    for cost_2 in range(num_constraints + 1):\n",
    "        for distance in range(num_qubits + 1):\n",
    "            # Should I np-ify all of the stuff here?\n",
    "            beta_factor = (np.cos(beta) ** (num_qubits - distance)) * ((-1j * np.sin(beta)) ** distance)\n",
    "            gamma_factor = np.exp(-1j * gamma * cost_2)\n",
    "            num_costs_at_distance = number_of_costs_at_distance_paper_proxy(cost_1, cost_2, distance, num_constraints, num_qubits)\n",
    "            sum += beta_factor * gamma_factor * prev_amplitudes[cost_2] * num_costs_at_distance\n",
    "    return sum\n",
    "\n",
    "\n",
    "# TODO: What if instead of optimizing expectation proxy we instead optimize high cost amplitudes (using e.g. exponential weighting)\n",
    "# Algorithm 1 from paper\n",
    "# num_constraints = number of edges, and num_qubits = number of vertices\n",
    "def QAOA_paper_proxy(p: int, gamma: np.ndarray, beta: np.ndarray, num_constraints: int, num_qubits: int):\n",
    "    num_costs = num_constraints + 1\n",
    "    amplitude_proxies = np.zeros([p + 1, num_costs], dtype=complex)\n",
    "    init_amplitude = np.sqrt(1 / (1 << num_qubits))\n",
    "    for i in range(num_costs):\n",
    "        amplitude_proxies[0][i] = init_amplitude\n",
    "\n",
    "    for current_depth in range(1, p + 1):\n",
    "        for cost_1 in range(num_costs):\n",
    "            amplitude_proxies[current_depth][cost_1] = compute_amplitude_sum_paper(\n",
    "                amplitude_proxies[current_depth - 1], gamma[current_depth - 1], beta[current_depth - 1], cost_1, num_constraints, num_qubits\n",
    "            )\n",
    "\n",
    "    expected_proxy = 0\n",
    "    for cost in range(num_costs):\n",
    "        expected_proxy += number_with_cost_paper_proxy(cost, num_constraints, num_qubits) * (abs(amplitude_proxies[p][cost]) ** 2) * cost\n",
    "\n",
    "    return amplitude_proxies, expected_proxy\n",
    "\n",
    "\n",
    "def inverse_paper_proxy_objective_function(num_constraints: int, num_qubits: int, p: int, expectations: list[np.ndarray] | None) -> typing.Callable:\n",
    "    def inverse_objective(*args) -> float:\n",
    "        gamma, beta = args[0][:p], args[0][p:]\n",
    "        _, expectation = QAOA_paper_proxy(p, gamma, beta, num_constraints, num_qubits)\n",
    "        current_time = time.time()\n",
    "\n",
    "        if expectations is not None:\n",
    "            expectations.append((current_time, expectation))\n",
    "\n",
    "        return -expectation\n",
    "\n",
    "    return inverse_objective\n",
    "\n",
    "\n",
    "def QAOA_paper_proxy_run(\n",
    "    num_constraints: int,\n",
    "    num_qubits: int,\n",
    "    p: int,\n",
    "    init_gamma: np.ndarray,\n",
    "    init_beta: np.ndarray,\n",
    "    optimizer_method: str = \"COBYLA\",\n",
    "    optimizer_options: dict | None = None,\n",
    "    expectations: list[np.ndarray] | None = None,\n",
    ") -> dict:\n",
    "    init_freq = np.hstack([init_gamma, init_beta])\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = scipy.optimize.minimize(\n",
    "        inverse_paper_proxy_objective_function(num_constraints, num_qubits, p, expectations),\n",
    "        init_freq,\n",
    "        args=(),\n",
    "        method=optimizer_method,\n",
    "        options=optimizer_options,\n",
    "    )\n",
    "    # the above returns a scipy optimization result object that has multiple attributes\n",
    "    # result.x gives the optimal solutionsol.success #bool whether algorithm succeeded\n",
    "    # result.message #message of why algorithms terminated\n",
    "    # result.nfev is number of iterations used (here, number of QAOA calls)\n",
    "    end_time = time.time()\n",
    "\n",
    "    def make_time_relative(input: tuple[float, float]) -> tuple[float, float]:\n",
    "        time, x = input\n",
    "        return (time - start_time, x)\n",
    "\n",
    "    if expectations is not None:\n",
    "        expectations = list(map(make_time_relative, expectations))\n",
    "\n",
    "    gamma, beta = result.x[:p], result.x[p:]\n",
    "    _, expectation = QAOA_paper_proxy(p, gamma, beta, num_constraints, num_qubits)\n",
    "\n",
    "    return {\n",
    "        \"gamma\": gamma,\n",
    "        \"beta\": beta,\n",
    "        \"expectation\": expectation,\n",
    "        \"runtime\": end_time - start_time,  # measured in seconds\n",
    "        \"num_QAOA_calls\": result.nfev,  # Calls to the proxy of course\n",
    "        \"classical_opt_success\": result.success,\n",
    "        \"scipy_opt_message\": result.message,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qokit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
